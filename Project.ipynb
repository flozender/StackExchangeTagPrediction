{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "# Spark imports\n",
    "import pyspark\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame, Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import desc\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col, expr, concat\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Word2Vec\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from collections import defaultdict\n",
    "\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6017243"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = init_spark()\n",
    "filename = \"./TrainWithoutBody.csv\"\n",
    "df1 = spark.read.option(\"multiLine\", 'true').option(\"escape\",\"\\'\").csv(filename, header=True)\n",
    "df1 = df1.drop(\"_c0\")\n",
    "df1 = df1.dropna()\n",
    "rddTags = df1.select(\"Tags\").rdd\n",
    "\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splittedTags = rddTags.filter(lambda r: r[0] != None).flatMap(lambda r: r[0].split(\" \")).map(lambda r: (r, 1)).reduceByKey(lambda x, y: x + y)\n",
    "splittedTags = splittedTags.sortBy(lambda r: r[1], False) #Sorted with number of usage (you can collect and see)\n",
    "splittedTagsSorted = splittedTags.map(lambda r: r[0]) #Delete this line if you want to see number of times they have been used.\n",
    "mostUsedTags = splittedTagsSorted.collect()[0:50]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec With Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 50\n",
    "classifier_array_title = []\n",
    "\n",
    "def column_splitter(r):\n",
    "    if not r.Tags:\n",
    "        label_array = None\n",
    "    else:\n",
    "        tags = r.Tags.split(' ')\n",
    "        label_array = []\n",
    "        for t in mostUsedTags:\n",
    "            if t in tags:\n",
    "                label_array.append(1)\n",
    "            else:\n",
    "                label_array.append(0)\n",
    "        if 1 not in label_array:\n",
    "            label_array = None\n",
    "    \n",
    "    return (r.Id, r.Title, r.Tags, r.tokenized_text, label_array)\n",
    "\n",
    "def init_spark_2():\n",
    "    spark = SparkSession \\\n",
    "        .builder.appName(\"W2V with Title\").config(\"spark.sql.broadcastTimeout\", \"72000\").config('spark.shuffle.service.enabled', 'TRUE').config(\"spark.debug.maxToStringFields\" , \"100\").config(\"spark.executor.heartbeatInterval\", \"14400\").getOrCreate()\n",
    "        \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='0', Id='1', Title='How to check if an uploaded file is an image without mime type?', Tags='php image-processing file-upload upload mime-types')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = init_spark_2()\n",
    "\n",
    "try:\n",
    "    filename1 = \"./TrainWithoutBody.csv\"\n",
    "    w2v_data_title = spark.read.option(\"multiLine\", 'true').option(\"escape\",\"\\'\").option(\"escape\",\"\\\"\").option(\"mode\", \"DROPMALFORMED\").csv(filename1, header=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "w2v_data_title.take(1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Featurization, Sampling and Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_title = Tokenizer(inputCol=\"Title\", outputCol=\"tokenized_text\")\n",
    "tokenized_df_title = tokenizer_title.transform(w2v_data_title)\n",
    "\n",
    "tokenized_df_title = tokenized_df_title.rdd.map(lambda r: column_splitter(r))\n",
    "tokenized_df_title = tokenized_df_title.toDF(['Id', 'Title', 'Tags', 'tokenized_text', 'tag_array'])\n",
    "tokenized_df_title = tokenized_df_title.drop(col('Title'))\n",
    "\n",
    "tokenized_df_title = tokenized_df_title.dropna()\n",
    "\n",
    "sampled_df_title = w2v_data_title.sample(False, 0.00083, seed=42)\n",
    "\n",
    "train_df_pre_title, test_val_df_title = sampled_df_title.randomSplit([.7,.3],seed=1234)\n",
    "test_df_pre_title, val_df_pre_title = test_val_df_title.randomSplit([.5, .5], seed=1234)\n",
    "\n",
    "word2Vec = Word2Vec(inputCol=\"tokenized_text\", outputCol=\"features\", vectorSize=100)\n",
    "fitted_word2Vec = word2Vec.fit(tokenized_df_title)\n",
    "\n",
    "train_df_pre_title = fitted_word2Vec.transform(train_df_pre_title)\n",
    "test_df_pre_title = fitted_word2Vec.transform(test_df_pre_title)\n",
    "val_df_pre_title = fitted_word2Vec.transform(val_df_pre_title)\n",
    "\n",
    "train_df_pre_title = train_df_pre_title.drop(col('tokenized_text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_pre_title.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate Label Array into Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id='1010021', Tags='objective-c ios asihttprequest mbprogresshud', features=DenseVector([0.1334, 0.1328, -0.0102, -0.0934, 0.0128, 0.0443, -0.0522, 0.0271, 0.0243, -0.0651, 0.0147, 0.096, -0.051, 0.0013, 0.0946, 0.002, 0.044, 0.0692, -0.0612, 0.0684, -0.185, -0.1426, 0.0978, -0.0974, 0.1009, 0.03, 0.0494, -0.1662, -0.1199, 0.0205, 0.0946, -0.0526, -0.0228, -0.0556, 0.016, 0.0649, 0.0587, -0.0064, 0.0571, 0.2185, -0.0653, 0.0316, -0.0888, -0.0019, -0.0207, -0.028, 0.0238, 0.0005, -0.0432, -0.0198, -0.0421, 0.0432, -0.1001, -0.0267, 0.1116, 0.0725, 0.1641, 0.0376, 0.0387, -0.0122, -0.0367, -0.1195, 0.1086, 0.0158, -0.0719, 0.1175, 0.1415, 0.076, -0.0416, -0.0258, 0.1169, 0.0997, 0.1299, -0.0532, -0.0107, 0.0317, -0.0595, -0.0329, 0.1416, -0.0224, -0.0705, -0.1555, -0.0044, -0.0675, -0.0367, -0.0667, -0.0863, -0.0146, -0.0121, -0.041, -0.0242, -0.1583, 0.0526, 0.0351, -0.1502, -0.0184, 0.0217, -0.0305, 0.0506, 0.0151]), c#=0, java=0, php=0, javascript=0, android=0, jquery=0, c++=0, python=0, iphone=0, aspnet=0, mysql=0, html=0, net=0, ios=1, objective-c=1, sql=0, css=0, linux=0, ruby-on-rails=0, windows=0, c=0, sql-server=0, ruby=0, wpf=0, xml=0, ajax=0, database=0, regex=0, windows-7=0, aspnet-mvc=0, xcode=0, django=0, osx=0, arrays=0, vbnet=0, eclipse=0, json=0, facebook=0, ruby-on-rails-3=0, ubuntu=0, performance=0, networking=0, string=0, multithreading=0, winforms=0, security=0, aspnet-mvc-3=0, visual-studio-2010=0, bash=0, homework=0)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_title = train_df_pre_title.select(['Id']+['Tags']+['features']+[expr('tag_array[' + str(x) + ']') for x in range(0, num_labels)])\n",
    "\n",
    "for i in range(0, num_labels): \n",
    "    if '.' in mostUsedTags[i]:\n",
    "        mostUsedTags[i] = mostUsedTags[i].replace('.', '')\n",
    "\n",
    "colnames = ['Id']+['Tags']+['features'] + [str(mostUsedTags[i]) for i in range(0, num_labels)] \n",
    "train_df_title = train_df_title.toDF(*colnames)\n",
    "\n",
    "train_df_title.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_lrs = defaultdict()\n",
    "\n",
    "w2v_dts = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "security\n",
      "aspnet-mvc-3\n",
      "visual-studio-2010\n",
      "bash\n",
      "homework\n"
     ]
    }
   ],
   "source": [
    "for tag in mostUsedTags:\n",
    "    if tag not in w2v_lrs:\n",
    "        w2v_lrs[tag] = LogisticRegression(maxIter=100, featuresCol='features', labelCol=tag, predictionCol='prediction').fit(train_df_title)\n",
    "        print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in mostUsedTags:\n",
    "    if tag not in w2v_dts:\n",
    "        w2v_dts[tag] = DecisionTreeClassifier(maxDepth=4, featuresCol='features', labelCol=tag, predictionCol='prediction').fit(train_df_title)\n",
    "        print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec With Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 50\n",
    "classifier_array = []\n",
    "def column_splitter(r):\n",
    "    if not r.Tags:\n",
    "        label_array = None\n",
    "    else:\n",
    "        tags = r.Tags.split(' ')\n",
    "        label_array = []\n",
    "        for t in mostUsedTags:\n",
    "            if t in tags:\n",
    "                label_array.append(1)\n",
    "            else:\n",
    "                label_array.append(0)\n",
    "        if 1 not in label_array:\n",
    "            label_array = None\n",
    "    \n",
    "    return (r.Id, r.Title, r.Tags, r.tokenized_text, label_array)\n",
    "\n",
    "def init_spark_3():\n",
    "    spark = SparkSession \\\n",
    "        .builder.appName(\"Python Spark SQL basic example\").config(\"spark.sql.broadcastTimeout\", \"72000\").config('spark.shuffle.service.enabled', 'TRUE').config(\"spark.debug.maxToStringFields\" , \"100\").config(\"spark.executor.heartbeatInterval\", \"14400\").getOrCreate()\n",
    "        \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id='1', Title=\"How to check if an uploaded file is an image without mime type?<p>I'd like to check if an uploaded file is an image file (e.g png, jpg, jpeg, gif, bmp) or another file. The problem is that I'm using Uploadify to upload the files, which changes the mime type and gives a 'text/octal' or something as the mime type, no matter which file type you upload.</p>\\n\\n<p>Is there a way to check if the uploaded file is an image apart from checking the file extension using PHP?</p>\\n\", Tags='php image-processing file-upload upload mime-types')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = init_spark_3()\n",
    "\n",
    "try:\n",
    "\n",
    "    filename1 = \"./Train.csv\"\n",
    "    w2v_data = spark.read.option(\"multiLine\", 'true').option(\"escape\",\"\\'\").option(\"escape\",\"\\\"\").option(\"mode\", \"DROPMALFORMED\").csv(filename1, header=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "w2v_data = w2v_data.withColumn('Title', concat(col('Title'), col('Body')))\n",
    "w2v_data = w2v_data.drop(col('Body'))\n",
    "\n",
    "w2v_data.take(1)\n",
    "\n",
    "# Another example\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Featurization, Sampling and Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|   Id|               Title|                Tags|      tokenized_text|           tag_array|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "| 7283|C# timers for mov...|c# animation time...|[c#, timers, for,...|[1, 0, 0, 0, 0, 0...|\n",
      "| 7396|I want to call Ht...|c# .net asp.net-m...|[i, want, to, cal...|[1, 0, 0, 0, 0, 0...|\n",
      "| 8282|Sending email wit...|  android oauth smtp|[sending, email, ...|[0, 0, 0, 0, 1, 0...|\n",
      "| 8977|How to monitor wh...|          c# windows|[how, to, monitor...|[1, 0, 0, 0, 0, 0...|\n",
      "| 9601|unity mesh collid...|        unity3d mesh|[unity, mesh, col...|[0, 0, 0, 0, 0, 0...|\n",
      "|10851|Is there any sett...|ruby-on-rails uni...|[is, there, any, ...|[0, 0, 0, 0, 0, 0...|\n",
      "|11099|Deep JSON Seriali...|java json jpa ser...|[deep, json, seri...|[0, 1, 0, 0, 0, 0...|\n",
      "|11638|Getting an inters...|google-places-api...|[getting, an, int...|[0, 0, 0, 0, 0, 0...|\n",
      "|13062|Turning on Window...|           windows-8|[turning, on, win...|[0, 0, 0, 0, 0, 0...|\n",
      "|13315|Mobile Safari onc...|javascript iphone...|[mobile, safari, ...|[0, 0, 0, 1, 0, 0...|\n",
      "|14695|Portable json mod...|json jython porta...|[portable, json, ...|[0, 0, 0, 0, 0, 0...|\n",
      "|14860|AVI -> WMV file -...|windows-7 video-e...|[avi, ->, wmv, fi...|[0, 0, 0, 0, 0, 0...|\n",
      "|15004|PropertyChanged e...|c# wpf binding ev...|[propertychanged,...|[1, 0, 0, 0, 0, 0...|\n",
      "|15346|Unique Hit counte...|    php html counter|[unique, hit, cou...|[0, 0, 1, 0, 0, 0...|\n",
      "|17425|WP highlight .cur...|           wordpress|[wp, highlight, ....|[0, 0, 0, 0, 0, 0...|\n",
      "|17809|How to Install ph...|    osx phpunit mamp|[how, to, install...|[0, 0, 0, 0, 0, 0...|\n",
      "|18260|How to handle boo...|ios5 xcode4.2 boo...|[how, to, handle,...|[0, 0, 0, 0, 0, 0...|\n",
      "|26503|becomeFirstRespon...|iphone ios ipad u...|[becomefirstrespo...|[0, 0, 0, 0, 0, 0...|\n",
      "|33695|Why does `Array(0...|arrays scala equa...|[why, does, `arra...|[0, 0, 0, 0, 0, 0...|\n",
      "|34855|Custom column sor...|       datagrid dojo|[custom, column, ...|[0, 0, 0, 0, 0, 0...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_df = w2v_data.sample(False, 0.00083, seed=42)\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"Title\", outputCol=\"tokenized_text\")\n",
    "tokenized_df = tokenizer.transform(sampled_df)\n",
    "\n",
    "tokenized_df = tokenized_df.rdd.map(lambda r: column_splitter(r))\n",
    "tokenized_df = tokenized_df.toDF(['Id', 'Title', 'Tags', 'tokenized_text', 'tag_array'])\n",
    "tokenized_df = tokenized_df.drop(col('Title'))\n",
    "\n",
    "tokenized_df = tokenized_df.dropna()\n",
    "\n",
    "tokenized_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_pre, test_val_df = tokenized_df.randomSplit([.7,.3],seed=1234)\n",
    "test_df_pre, val_df_pre = test_val_df.randomSplit([.5, .5], seed=1234)\n",
    "\n",
    "word2Vec = Word2Vec(inputCol=\"tokenized_text\", outputCol=\"features\", vectorSize=100)\n",
    "fitted_word2Vec = word2Vec.fit(tokenized_df)\n",
    "\n",
    "train_df_pre = fitted_word2Vec.transform(train_df_pre)\n",
    "test_df_pre = fitted_word2Vec.transform(test_df_pre)\n",
    "val_df_pre = fitted_word2Vec.transform(val_df_pre)\n",
    "\n",
    "train_df_pre = train_df_pre.drop(col('tokenized_text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     Id|               Title|                Tags|           tag_array|            features|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|1005960|When evaluating a...|                   c|[0, 0, 0, 0, 0, 0...|[-0.0177763070276...|\n",
      "|1006700|Delete files in t...|      windows folder|[0, 0, 0, 0, 0, 0...|[-0.0656386298768...|\n",
      "| 100767|Reference existin...|c# entity-framewo...|[1, 0, 0, 0, 0, 0...|[0.09648928268901...|\n",
      "|1007785|How to search (us...|  regex vim escaping|[0, 0, 0, 0, 0, 0...|[-0.1014933573348...|\n",
      "|1008518|Cucumber and vari...|   ruby tdd cucumber|[0, 0, 0, 0, 0, 0...|[0.02025146771946...|\n",
      "|1010686|How to get common...|                 sql|[0, 0, 0, 0, 0, 0...|[-0.0140362187506...|\n",
      "|1011820|joining two table...|                tsql|[0, 0, 0, 0, 0, 0...|[0.07489425870370...|\n",
      "|1012944|console.dir(windo...|javascript firefo...|[0, 0, 0, 1, 0, 0...|[-0.0454304110209...|\n",
      "|1014555|Share dependencie...|       maven maven-3|[0, 0, 0, 0, 0, 0...|[-0.0903882682042...|\n",
      "|1014790|Is it possible to...|     java javascript|[0, 1, 0, 1, 0, 0...|[-0.1109096599933...|\n",
      "|1016070|Installed ColdFus...|          coldfusion|[0, 0, 0, 0, 0, 0...|[-0.1108543918522...|\n",
      "|1016894|images duplicatin...|image uitableview...|[0, 0, 0, 0, 0, 0...|[0.13776769980895...|\n",
      "|1017844|Replacing each ma...|        python regex|[0, 0, 0, 0, 0, 0...|[-0.0688972459827...|\n",
      "|1017973|Sub-additivity of...|      measure-theory|[0, 0, 0, 0, 0, 0...|[-0.0627923144412...|\n",
      "|1020796|Select all users ...|mysql sql select ...|[0, 0, 0, 0, 0, 0...|[-0.0637138005292...|\n",
      "|1021623|Passing different...|ruby-on-rails for...|[0, 0, 0, 0, 0, 0...|[-0.1065407096913...|\n",
      "|1024039|Send custom confi...|ruby-on-rails aut...|[0, 0, 0, 0, 0, 0...|[-0.1088191762450...|\n",
      "|1025715|How to create use...|       linux centos5|[0, 0, 0, 0, 0, 0...|[-0.1180206482556...|\n",
      "|1026645|UMDF Development ...|c# .net drivers umdf|[1, 0, 0, 0, 0, 0...|[-0.1032163758339...|\n",
      "|1026648|Convert SVG image...|php svg imagemagi...|[0, 0, 1, 0, 0, 0...|[-0.1056499650784...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df_pre.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate Labels into Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df_pre.select(['Id']+['Title']+['Tags']+['features']+[expr('tag_array[' + str(x) + ']') for x in range(0, num_labels)])\n",
    "\n",
    "for i in range(0, num_labels): \n",
    "    if '.' in mostUsedTags[i]:\n",
    "        mostUsedTags[i] = mostUsedTags[i].replace('.', '')\n",
    "\n",
    "colnames = ['Id']+['Title']+['Tags']+['features'] + [str(mostUsedTags[i]) for i in range(0, num_labels)] \n",
    "train_df = train_df.toDF(*colnames)\n",
    "\n",
    "train_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_lrs_body = defaultdict()\n",
    "\n",
    "w2v_dts_body = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in mostUsedTags:\n",
    "    if tag not in w2v_lrs_body:\n",
    "        w2v_lrs_body[tag] = LogisticRegression(maxIter=100, featuresCol='features', labelCol=tag, predictionCol='prediction').fit(train_df)\n",
    "        print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in mostUsedTags:\n",
    "    if tag not in w2v_dts_body:\n",
    "        w2v_dts_body[tag] = DecisionTreeClassifier(maxDepth=4, featuresCol='features', labelCol=tag, predictionCol='prediction').fit(train_df)\n",
    "        print(tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
