{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "# Spark imports\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame, Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import desc\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col, expr\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Word2Vec\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy \n",
    "\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Font size=5 color=red>Investigate the original dataset (obviously, it cannot be used). Take a look at https://stackoverflow.com/questions/13793529/r-error-invalid-type-list-for-variable to see how useless the Body column information could be!\n",
    "\n",
    "The point here is that the body information consists mostly of codes and some weird patterns that are not useful for our purpose. The most important information here is the connection between the title of the questions and tags. So, I removed the Body column from the dataset.</Font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62819203\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                  Id|               Title|                Body|                Tags|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                   1|How to check if a...|<p>I'd like to ch...|php image-process...|\n",
      "|                   2|How can I prevent...|<p>In my favorite...|             firefox|\n",
      "|                   3|R Error Invalid t...|\"<p>I am import m...|                null|\n",
      "|      expert_trai...|                null|                null|                null|\n",
      "|      expert_data...|                null|                null|                null|\n",
      "|      rf_model = ...| data=expert_data...|     importance=TRUE|      do.trace=100);|\n",
      "|                   }|                null|                null|                null|\n",
      "|       </code></pre>|                null|                null|                null|\n",
      "|<p>Structure of t...|                null|                null|                null|\n",
      "|<pre><code>[56x12...|                null|                null|                null|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark = init_spark()\n",
    "\n",
    "    filename1 = \"./Train.csv\"\n",
    "    df2 = spark.read.option(\"multiLine\", 'true').option(\"escape\",\"\\'\").csv(filename1, header=True)\n",
    "    print(df2.count())\n",
    "    print(df2.show(10))    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Font size=5 color=red>For removing the Body column, I read all the dataset once using Pandas library. After that, I removed the column and got an export to have a concrete file as our dataset. This part has been ommited from the notebook.</Font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6017243"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = init_spark()\n",
    "\n",
    "filename = \"./TrainWithoutBody.csv\"\n",
    "df1 = spark.read.option(\"multiLine\", 'true').option(\"escape\",\"\\'\").csv(filename, header=True)\n",
    "df1 = df1.drop(\"_c0\")\n",
    "df1 = df1.dropna()\n",
    "\n",
    "rddTags = df1.select(\"Tags\").rdd\n",
    "\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| Id|               Title|                Tags|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|How to check if a...|php image-process...|\n",
      "|  2|How can I prevent...|             firefox|\n",
      "|  3|R Error Invalid t...|r matlab machine-...|\n",
      "|  4|How do I replace ...|     c# url encoding|\n",
      "|  5|How to modify who...|php api file-get-...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Font size = 5, color=green>Finding the 100 most used tags (one DT per each most used tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splittedTags = rddTags.filter(lambda r: r[0] != None).flatMap(lambda r: r[0].split(\" \")).map(lambda r: (r, 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "splittedTags = splittedTags.sortBy(lambda r: r[1], False) #Sorted with number of usage (you can collect and see)\n",
    "\n",
    "splittedTagsSorted = splittedTags.map(lambda r: r[0]) #Delete this line if you want to see number of times they have been used.\n",
    "\n",
    "# df10 = anSorted.toDF()\n",
    "\n",
    "\n",
    "mostUsedTags = splittedTagsSorted.collect()[0:50]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c#',\n",
       " 'java',\n",
       " 'php',\n",
       " 'javascript',\n",
       " 'android',\n",
       " 'jquery',\n",
       " 'c++',\n",
       " 'python',\n",
       " 'iphone',\n",
       " 'asp.net',\n",
       " 'mysql',\n",
       " 'html',\n",
       " '.net',\n",
       " 'ios',\n",
       " 'objective-c',\n",
       " 'sql',\n",
       " 'css',\n",
       " 'linux',\n",
       " 'ruby-on-rails',\n",
       " 'windows',\n",
       " 'c',\n",
       " 'sql-server',\n",
       " 'ruby',\n",
       " 'wpf',\n",
       " 'xml',\n",
       " 'ajax',\n",
       " 'database',\n",
       " 'regex',\n",
       " 'windows-7',\n",
       " 'asp.net-mvc',\n",
       " 'xcode',\n",
       " 'django',\n",
       " 'osx',\n",
       " 'arrays',\n",
       " 'vb.net',\n",
       " 'eclipse',\n",
       " 'json',\n",
       " 'facebook',\n",
       " 'ruby-on-rails-3',\n",
       " 'ubuntu',\n",
       " 'performance',\n",
       " 'networking',\n",
       " 'string',\n",
       " 'multithreading',\n",
       " 'winforms',\n",
       " 'security',\n",
       " 'asp.net-mvc-3',\n",
       " 'visual-studio-2010',\n",
       " 'bash',\n",
       " 'homework']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostUsedTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6017243\n"
     ]
    }
   ],
   "source": [
    "print(rddTags.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Tags='php image-processing file-upload upload mime-types'),\n",
       " Row(Tags='firefox'),\n",
       " Row(Tags='r matlab machine-learning'),\n",
       " Row(Tags='c# url encoding'),\n",
       " Row(Tags='php api file-get-contents'),\n",
       " Row(Tags='proxy active-directory jmeter'),\n",
       " Row(Tags='core-plot'),\n",
       " Row(Tags='c# asp.net windows-phone-7'),\n",
       " Row(Tags='.net javascript code-generation'),\n",
       " Row(Tags='sql variables parameters procedure calls')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddTags.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Font size=5.5, color=\"purpule\">Here, I have cleaned the Tags column to only contain the most used tags. For example, I ommited the \"upload\" tag from first group of tags for the first question, because it's not a most used tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceNoneWithString(x):\n",
    "    if (x == None): return \"None\"\n",
    "    else : return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrr = rddTags.map(lambda r: r[0]).map(replaceNoneWithString).map(lambda r: r.split(\" \")).map(lambda r: [ped for ped in r if ped in mostUsedTags])\n",
    "cleanedTags = rrr.take(10)\n",
    "cleanedTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject titles to TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Title\", outputCol=\"transformed_tfidf\")\n",
    "wordsData = tokenizer.transform(df1)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"transformed_tfidf\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "featurizedData.take(1)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|                tags|            features|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|php image-process...|(20,[1,3,4,8,9,10...|\n",
      "|  2|             firefox|(20,[1,2,3,7,12,1...|\n",
      "|  3|r matlab machine-...|(20,[2,4,5,6,7,17...|\n",
      "|  4|     c# url encoding|(20,[3,6,7,10,13,...|\n",
      "|  5|php api file-get-...|(20,[3,5,8,13,15,...|\n",
      "|  6|proxy active-dire...|(20,[0,3,4,7,13,1...|\n",
      "|  7|           core-plot|(20,[3,6,7,8,10,1...|\n",
      "|  8|c# asp.net window...|(20,[0,3,7,8,10,1...|\n",
      "|  9|.net javascript c...|(20,[0,1,3,4],[1....|\n",
      "| 10|sql variables par...|(20,[0,3,6,12,16,...|\n",
      "| 11|.net obfuscation ...|(20,[0,3,6,8,11,1...|\n",
      "| 12|algorithm languag...|(20,[0,1,5,19],[1...|\n",
      "| 13|postfix migration...|(20,[1,3,8,18,19]...|\n",
      "| 14|documentation lat...|(20,[10,13,16,17,...|\n",
      "| 15|           windows-7|(20,[1,2,12,13,15...|\n",
      "| 16|php url-routing c...|(20,[2,4,10,18],[...|\n",
      "| 17|   r temporary-files|(20,[3,5,8,13,15,...|\n",
      "| 18|         wpf binding|(20,[0,8,12,13,15...|\n",
      "| 19|javascript code-g...|(20,[6,11,13,14,1...|\n",
      "| 20|php xml hash mult...|(20,[1,2,7,8,10,1...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Id='1', Title='How to check if an uploaded file is an image without mime type?', Tags='php image-processing file-upload upload mime-types', transformed_tfidf=['how', 'to', 'check', 'if', 'an', 'uploaded', 'file', 'is', 'an', 'image', 'without', 'mime', 'type?'], rawFeatures=SparseVector(20, {1: 1.0, 3: 3.0, 4: 1.0, 8: 2.0, 9: 1.0, 10: 2.0, 12: 2.0, 16: 1.0}), features=SparseVector(20, {1: 1.1357, 3: 1.8792, 4: 1.1753, 8: 1.4617, 9: 1.1974, 10: 2.0765, 12: 2.0979, 16: 0.9553}))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledData.select(\"id\", \"tags\", \"features\").show()\n",
    "rescaledData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject titles to Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Title\", outputCol=\"tokenized_text\")\n",
    "tokenized_df = tokenizer.transform(df1)\n",
    "\n",
    "word2Vec = Word2Vec(inputCol=\"tokenized_text\", outputCol=\"features\", vectorSize=100)\n",
    "w2v_model = word2Vec.fit(tokenized_df)\n",
    "w2v_data = w2v_model.transform(tokenized_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df1.sample(False, 0.0083, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampled Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_sampled = Tokenizer(inputCol=\"Title\", outputCol=\"tokenized_text\")\n",
    "tokenized_df_sampled = tokenizer_sampled.transform(sampled_df)\n",
    "\n",
    "word2Vec_sampled = Word2Vec(inputCol=\"tokenized_text\", outputCol=\"features\", vectorSize=100)\n",
    "w2v_model_sampled = word2Vec_sampled.fit(tokenized_df_sampled)\n",
    "w2v_data_sampled = w2v_model_sampled.transform(tokenized_df_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id='256', Title='How to figure out all colors in a gradient?', Tags='javascript html html5 colors mobile-safari', tokenized_text=['how', 'to', 'figure', 'out', 'all', 'colors', 'in', 'a', 'gradient?'], features=DenseVector([-0.0886, -0.0275, -0.0055, -0.1521, 0.0222, -0.0349, -0.0111, -0.0664, -0.007, -0.0018, -0.0511, 0.0199, 0.0044, 0.0184, 0.0305, -0.0008, 0.0784, 0.0005, 0.0343, 0.0095, -0.104, -0.0573, 0.0101, -0.0103, 0.0158, -0.0487, -0.0471, 0.0364, -0.0332, -0.0173, -0.0651, -0.0013, 0.0944, 0.0042, -0.0048, 0.0996, 0.0109, -0.0997, -0.037, 0.0819, 0.0627, -0.0586, 0.0279, -0.008, 0.0465, -0.0168, -0.0181, 0.0759, -0.0275, 0.0039, 0.0801, 0.0612, 0.0232, -0.0785, -0.0415, 0.0093, 0.0227, 0.0236, 0.1114, -0.1044, 0.0061, -0.049, 0.1084, 0.0929, -0.0442, -0.0572, 0.0531, 0.0711, 0.0156, 0.0831, 0.0194, 0.0806, -0.0228, 0.0172, -0.0613, 0.0158, -0.1076, -0.0305, 0.0112, 0.064, -0.035, -0.0226, -0.0497, -0.0714, -0.0668, -0.0185, 0.0443, 0.118, 0.1433, -0.0684, -0.0112, -0.0042, 0.0182, 0.0439, -0.0743, 0.0433, 0.0393, 0.0196, 0.0155, 0.0407]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_data_sampled.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(r):\n",
    "    tags = r.labels\n",
    "    labels = []\n",
    "    for t in mostUsedTags:\n",
    "        if t in tags:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return (r.Id, r.Title, r.features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Result Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+\n",
      "|  Id|               Title|            features|              labels|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "| 256|How to figure out...|[-0.0886373691674...|[0, 0, 0, 1, 0, 0...|\n",
      "| 314|Save loop deletin...|[-0.0853397778959...|[0, 0, 0, 0, 0, 0...|\n",
      "| 396|Magento how to mo...|[-0.0964386757049...|[0, 0, 1, 0, 0, 0...|\n",
      "| 713|Installing Numpy ...|[0.08249647377265...|[0, 0, 0, 0, 0, 0...|\n",
      "|1200|Return values fro...|[-0.0844753608107...|[0, 1, 0, 0, 0, 0...|\n",
      "|1209|Emulating varianc...|[-0.0069562578573...|[1, 0, 0, 0, 0, 0...|\n",
      "|1345|android network a...|[0.03282853712638...|[0, 0, 0, 0, 1, 0...|\n",
      "|1406|Significance Tests R|[-0.0210384248445...|[0, 0, 0, 0, 0, 0...|\n",
      "|1440|Calling a functio...|[-0.0376302030765...|[0, 0, 0, 0, 0, 0...|\n",
      "|1449|jQuery running fu...|[-0.0372561349843...|[0, 0, 0, 0, 0, 1...|\n",
      "|1523|in grails ,how us...|[-0.0155541035087...|[0, 0, 0, 0, 0, 0...|\n",
      "|1644|Why do my black l...|[-0.0386486240895...|[0, 0, 0, 0, 0, 0...|\n",
      "|1692|How to get all co...|[-0.1084294123575...|[0, 0, 1, 0, 0, 0...|\n",
      "|1694|Generate a random...|[-0.0785088919930...|[0, 0, 0, 0, 0, 0...|\n",
      "|1717|Linq: assign vari...|[-0.0364652788266...|[1, 0, 0, 0, 0, 0...|\n",
      "|1825|Amazon EC2 Linux ...|[-0.0408333057227...|[0, 0, 1, 0, 0, 0...|\n",
      "|1925|Creating files in...|[-0.0304778761540...|[0, 0, 0, 0, 0, 0...|\n",
      "|2100|\"\"\"JSR-303 Provid...|[0.00966400792822...|[0, 1, 0, 0, 0, 0...|\n",
      "|2149|Best way to add s...|[-0.0742940711609...|[0, 0, 0, 1, 0, 1...|\n",
      "|2364|variables used in...|[-0.0426419798284...|[0, 0, 0, 0, 0, 0...|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_tags = w2v_data_sampled.withColumn('labels', split(col(\"Tags\"),\" \"))\n",
    "w2v_with_targets = target_tags.rdd.map(lambda r: my_function(r))\n",
    "train_cols = [\"Id\",\"Title\", \"features\", \"labels\"]\n",
    "train_df = w2v_with_targets.toDF(train_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate Labels into Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_colnames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-ee60b66e5ec0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels['\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m']'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcolnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmostUsedTags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_colnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_colnames' is not defined"
     ]
    }
   ],
   "source": [
    "arr_size = 50\n",
    "train_df = train_df.select(['Id']+['Title']+['features']+['labels']+[expr('labels[' + str(x) + ']') for x in range(0, arr_size)])\n",
    "colnames = ['Id']+['Title']+['features']+['labels'] + [str(mostUsedTags[i]) for i in range(0, arr_size)] \n",
    "train_df = df.toDF(*colnames)\n",
    "train_df.take(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
